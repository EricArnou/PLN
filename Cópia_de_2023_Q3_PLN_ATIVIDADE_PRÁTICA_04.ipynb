{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Fu0clU4eDW9j",
        "WQ_MJ8XHDCWv",
        "9SgeA_JAGPb1",
        "Az7jp0UaGrxi"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricArnou/PLN/blob/main/C%C3%B3pia_de_2023_Q3_PLN_ATIVIDADE_PR%C3%81TICA_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 04 [Uso da API da OpenAI com técnicas de PLN]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 04** deve ser feita utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/GzwCq3R7ExtE9g9a8\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia 20/11 (segunda-feira) APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Eric Arnou Santos e RA: 11201921685`\n"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo: 1`\n",
        "\n",
        "`Segundo capítulo: 25`\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso da **API da OpenAI** aplicando, no mínimo, 3 técnicas de PLN. As técnicas devem ser aplicadas nos 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        ">\n",
        "\n",
        "**RESTRIÇÃO**: É obrigatório usar o *endpoint* \"*`Chat Completions`*\".\n",
        "\n",
        ">\n",
        "\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   **Similaridade de Textos**\n",
        "*   **Reconhecimento de Entidades Nomeadas**\n",
        "*   **Sistemas de Perguntas e Respostas**\n",
        "\n",
        ">\n",
        "\n",
        "Os capítulos devem ser os mesmos selecionados na **ATIVIDADE PRÁTICA 02**. Para consultar os capítulos, considere a seguinte planilha:\n",
        "\n",
        ">\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC. Não é permitido alterar os capítulos já selecionados.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serão considerados como critérios de avaliação as técnicas usadas e a criatividade envolvida na aplicação das mesmas.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Textos dos capítulos"
      ],
      "metadata": {
        "id": "Fu0clU4eDW9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Criação das variaveis cap1 e cap25 que recebem em string os dois capitulos que foram extraidos na atividade anterior\n",
        "\n",
        "cap1 = \"Processamento de Linguagem Natural (PLN) é um campo de pesquisa que tem como objetivo investigar e propor métodos e sistemas de processamento computacional da linguagem humana. O adjetivo “Natural”, na sigla, se refere às línguas faladas pelos humanos, distinguindo-as das demais linguagens (matemáticas, visuais, gestuais, de programação etc.). No decorrer deste livro, os termos “língua”, “linguagem humana” e “linguagem natural” serão usados indistintamente; já “linguagem” pode eventualmente se referir a qualquer tipo de linguagem. Na área da Ciência da Computação, PLN está ligado à área de Inteligência Artificial (IA) e também está intrinsecamente relacionada à Linguística Computacional.Para deixar mais claro o que entendemos por PLN, vamos esclarecer o que se faz nessa área. De modo geral, em PLN buscam-se soluções para problemas computacionais, ou seja, tarefas, sistemas, aplicações ou programas, que requerem o tratamento computacional de uma língua (português, inglês etc.), seja escrita (texto) ou falada (fala). Línguas como as de sinais também têm sido alvo de estudos da área. Cada modo tem suas especificidades. No caso da fala, as características que a distinguem da língua escrita são relacionadas a questões da produção (síntese) e recepção (reconhecimento) do som. Recursos da fala, como a entonação, o volume, o sotaque, podem tanto dificultar o reconhecimento ou a síntese, como também facilitar o reconhecimento de sentimentos ou intenções do falante. Qualquer que seja o modo, fala, escrita, línguas orais e línguas de sinais compartilham a dificuldade maior em PLN: a apreensão do significado de uma expressão linguística. Isso vai ficar claro no decorrer deste livro.O PLN se divide em duas grandes subáreas: Interpretação (ou Compreensão) de Linguagem Natural – NLU (do inglês, Natural Language Understanding), e Geração de Linguagem Natural – NLG (do inglês, Natural Language Generation)1.Situa-se em NLU tudo o que diz respeito ao processamento que visa à análise e à interpretação da língua. Por análise, entende-se a segmentação e classificação dos componentes linguísticos (p. ex. palavras e suas classes morfológicas e gramaticais, seus traços semânticos ou ontológicos etc.). Já interpretação se refere à tentativa de apreender significados construídos pelo ser humano. Numa interação com um chatbot, por exemplo, a interpretação ocorre quando o sistema processa um texto do usuário para descobrir o que ele – o sistema – deve fazer a seguir: se fornecer uma resposta ou executar uma ação. Logo ficará claro que respostas mais ou menos bem-sucedidas do sistema para o significado tencionado pelo humano podem ser suficientes para muitas aplicações, e que o completo alinhamento entre o significado tencionado pelo humano e aquele interpretado pela máquina não deve ser parte das nossas expectativas.Em NLG, por outro lado, o objetivo é a geração de linguagem natural. Um exemplo de NLG é a geração de respostas ao usuário dos chatbots. Para o sistema, isso significa decidir o que responder e como apresentar essa resposta ao usuário. Atualmente, o ChatGPT2 é o exemplo de maior sucesso: é capaz de gerar língua de forma tão ou mais fluente quanto muitos humanos.É importante esclarecer, desde já, alguns conceitos amplamente usados no decorrer deste livro. Eles dizem respeito à classificação de alguns sistemas de PLN quanto ao seu uso.Esses conceitos são: aplicações, recursos e ferramentas.Primeiramente, é relevante observar como esses conceitos se relacionam entre si. A Figura 1.1 esquematiza essa dinâmica.Como vemos na Figura 1.1, em PLN as ferramentas auxiliam na construção de uma aplicação, que pode ser um sistema computacional (desktop, web) ou um aplicativo. As aplicações fornecem um resultado ao usuário tendo uma entrada (input) ou saída (output) em linguagem natural. Aplicações fazem uso de ferramentas ou conjuntos de ferramentas, conhecidos como “toolkits”. Também necessitam recursos, os quais fornecem informações linguísticas necessárias para que as aplicações consigam processar a língua da maneira adequada.É importante notar que a denominação utilizada – aplicação, recurso ou ferramenta – é imprecisa e depende do uso. Por exemplo, um corretor ortográfico pode ser uma aplicação a ser usada de forma autônoma ou um passo intermediário para uma aplicação de correção de redações; um tradutor automático pode ser uma aplicação em si, com uma interface para colocar um texto de entrada e obter um texto de saída, mas também pode ser usado como ferramenta para traduzir um corpus de uma língua para outra, visando a criação de recursos em línguas de comunidades tecnologicamente menos desenvolvidas; um sumarizador automático pode ser usado para criar resumos para um usuário qualquer, mas também pode ser usado por um buscador da web como passo intermediário para um sistema de recuperação de informação; um dicionário é um recurso, mas também pode ser usado como um aplicativo para consulta; um modelo de língua pode se transformar num chatbot, e assim por diante. Os conceitos são caracterizados e exemplificados no Quadro 1.1.Quadro 1.1 Exemplos de aplicações, recursos e ferramentasNeste livro iremos aumentar gradativamente a complexidade do tratamento da língua no PLN, com foco no português brasileiro. Antes de iniciar esta trajetória, a Seção 1.2 apresenta nosso objeto de pesquisa, a língua. Em seguida, a Seção 1.3 introduz os principais paradigmas do PLN, que serão retomados em diversos momentos neste livro. Por fim, a Seção 1.4 destaca os principais pontos apresentados no capítulo.A capacidade de usarmos a linguagem para representar nossa realidade e nos comunicar é algo que distingue o ser humano dos outros seres vivos. Poder criar significados, expressar-se e ser compreendida é um dos grandes avanços no desenvolvimento de uma criança. Nos primeiros anos de vida, um bebê vai adquirindo a habilidade de se expressar em sua língua materna. Anos depois, normalmente a criança adquire a capacidade de utilizar símbolos para registrar aquilo que ela deseja por meio da língua escrita. A língua, como um sistema de construção de representações do mundo e comunicação, sobretudo no modo escrito, é o foco deste livro.Ao longo do livro, nosso foco predominante será a língua escrita4, ou seja, sequências de caracteres representados de forma grafológica, os quais constroem significados para nós humanos. Em PLN, chamamos a língua escrita de texto, para distingui-la da linguagem oral, que é chamada de fala. Portanto, apesar de a linguística reconhecer que existem textos escritos e textos falados, em PLN a palavra texto se refere principalmente ao texto escrito. Em relação à língua, neste livro, os exemplos estão em português brasileiro, embora muitas das técnicas descritas aqui possam ser aplicadas a outros idiomas.A linguagem humana organiza-se em diferentes dimensões. A Figura 1.2 mostra uma representação das subáreas que estudam o sistema linguístico.Na Figura 1.2, a língua é representada por meio de círculos concêntricos, sendo cada um deles objeto de estudo de uma subárea dos estudos linguísticos. No núcleo, os sons e sua organização são estudados pela fonética e pela fonologia. Envolvendo a estrutura sonora, temos o estudo de como os morfemas se organizam para formar palavras, que é objeto de estudo da morfologia. Envolvendo a morfologia, temos o estudo de como as palavras se organizam em estruturas para formar sintagmas e orações, objeto de estudo da sintaxe. No círculo envolvendo a sintaxe, temos a semântica, que estuda o significado de palavras e frases, enquanto a pragmática enfoca como as orações são utilizadas na interação para fins comunicativos específicos. Já discurso é uma denominação que abrange os estudos com foco no texto como um todo, podendo se referir à análise das relações entre frases ou partes de um texto, ou das etapas na estrutura de um texto.Cada língua tem suas especificidades que determinam, por exemplo, desde como os caracteres podem ser combinados para compor uma palavra (uma sequência válida que tenha significado naquela língua) até regras que definem a estrutura (sintaxe) dessa língua. No decorrer deste livro, serão abordados os desafios do PLN em cada uma dessas subáreas. Contudo, é importante que fique claro que as estratégias computacionais usadas para o processamento da linguagem muitas vezes utilizam conhecimentos de várias subáreas ao mesmo tempo. Por exemplo, no processamento morfossintático realizado por um etiquetador (tagger), informações morfológicas e sintáticas são consideradas para se determinar a categoria gramatical (part-of-speech, PoS) de uma palavra.Até a década de 1980, o PLN se baseava no que chamamos de paradigma simbólico, segundo o qual todo conhecimento sobre a língua é expresso explicitamente em formalismos como léxicos, regras, linguagens lógicas etc., ou seja, formas compreensíveis ao humano. Por exemplo, é possível escrever regras que determinem que, em português, há concordância entre o gênero gramatical atribuído a um substantivo e o gênero atribuído ao adjetivo que o acompanha. Assim, exemplos como “abacaxi maduro” serão considerados corretos de acordo com essa regra, enquanto que outros, como “abacaxi madura”, não.No início dos anos 1990, as máquinas ganharam mais capacidade de memória e processamento, e diversos algoritmos de aprendizado de máquina foram propostos dando origem ao que chamamos de paradigma estatístico. Grandes conjuntos de textos (também chamados de corpus) passaram a ser usados como fonte de conhecimento para “ensinar” as máquinas. Por exemplo, fenômenos como a concordância entre substantivo e adjetivo, mencionada anteriormente, passaram a ser aprendidos a partir de exemplos de ocorrência no corpus como: “tomate estragado”, “kiwi maduro”, “gergelim preto”. A língua é, então, representada em modelos probabilísticos aprendidos a partir da frequência de ocorrência. Regras explícitas ou implícitas (percursos em árvores, por exemplo) são criadas com base em probabilidades calculadas a partir dos exemplos. Esses modelos são usados para classificar, resumir, traduzir ou gerar novos textos. Uma vez que esses modelos são aprendidos a partir de dados reais, eles têm uma grande chance de serem bons modelos da língua. A tradução automática foi a aplicação de PLN que deu notoriedade a esse paradigma estatístico, que era o mais aplicado até a década de 2010.O tempo passou e as máquinas continuam ganhando poder de memória e processamento, o que possibilita que grandes quantidades de dados sejam processadas por estruturas (arquiteturas e algoritmos) bastante complexas, como as Redes Neurais Profundas (conhecidas em inglês como deep learning). No momento da escrita deste capítulo, o paradigma neural é o mais adotado para tarefas de PLN. Da mesma forma que o paradigma estatístico, as redes neurais também se baseiam em grandes volumes de dados para aprender um modelo; contudo, a forma como esse aprendizado é realizado é diferente, uma vez que envolve várias camadas de unidades de processamento para reconhecer os padrões recorrentes. Assim, enquanto em outras técnicas de aprendizado de máquina (machine learning) tradicional (shallow ou baseado em features) os algoritmos especificam como o aprendizado deve ocorrer, no deep learning, devido à complexidade das arquiteturas compostas por diversas camadas de processamento, não é possível saber exatamente com base em quê o modelo foi aprendido. Além disso, diferentemente do paradigma simbólico, no paradigma neural, o conhecimento da língua é dado por valores numéricos, e não por símbolos ou regras. Dessa forma, o conhecimento linguístico ou a parte do código que tenha produzido um determinado comportamento são praticamente irrecuperáveis, tornando o código opaco, e seu efeito, não previsível (não determinístico).Nesse sentido, pode-se notar que o PLN tem acompanhado a evolução de paradigmas da IA: simbólico, estatístico e neural. Porém, diante da insuficiência de uma única abordagem, ganham espaço os paradigmas híbridos, que combinam principalmente o simbólico com um dos demais, garantindo, assim, alguma explicitação do conhecimento, consequentemente, alguma explicabilidade dos passos seguidos pelos algoritmos.Além da IA, o PLN tem intersecção com diversos campos de pesquisa e de aplicação no mercado de trabalho como mineração de textos, recuperação de informação e ciência de dados. Na atualidade, todas as aplicações computacionais que processam texto são passíveis de utilizar em maior ou menor grau as técnicas de PLN.Antes de passarmos para os próximos capítulos deste livro, seguem algumas considerações importantes:Embora algumas siglas, como NLP (Natural Language Processing) e AI (Artificial Intelligence) tenham sido traduzidas e sejam amplamente utilizadas em português, as siglas NLU e NLG são utilizadas, em textos em português, em sua grafia inglesa.\"\n",
        "\n",
        "cap25 = \"Neste último Capítulo elencamos alguns desafios e perspectivas para o PLN em língua portuguesa e finalizamos com uma discussão sobre os limites atuais do PLN.Por razões históricas e econômicas, os sistemas atuais de PLN “estado da arte” são muito mais comuns em inglês do que em qualquer outra língua. Enquanto que outras comunidades têm adaptado para suas línguas os sistemas originalmente criados para o inglês (por meio de novos treinamentos, mas com aproveitamento de parâmetros), comunidades linguísticas minoritárias e comunidades linguísticas de países menos desenvolvidos são invisibilizadas no mundo digital, com consequências negativas e diretas na sua economia e desenvolvimento.Segundo o Instituto Camões, em 2022, a comunidade de falantes de português no mundo era estimada em cerca de 260 milhões de pessoas (3,7% da população mundial) sendo o quarto idioma mais usado, depois do mandarim, inglês e espanhol. Contudo, essa representatividade não é contemplada no estado da arte da ciência, que está majoritariamente nas mãos de instituições e organizações não falantes do português. Pesquisadores brasileiros e portugueses têm levantado a necessidade de unir forças para colocar o português no lugar de destaque que ele merece1.O processamento do português brasileiro tem avançado de maneira consistente desde meados da década de 1990, principalmente a partir do uso de AM e de abordagens cross-language e multilíngue, que facilitam a construção rápida de recursos e soluções, e permitem a geração de uma aplicação em uma língua a partir de uma aplicação em outra língua. Mas ainda é precária a união de esforços entre os países da Comunidade de Países de Língua Portuguesa (CPLP), que inclui Portugal, Angola, Moçambique, Cabo Verde, Guiné-Bissau, São Tomé e Príncipe, além do Brasil. Se as diferenças linguísticas entre os diferentes idiomas representam barreiras para a criação de sistemas comuns, não há dúvida de que a união de esforços trará benefícios para todos. Por ora, o esforço mais visível é aquele entre os mais fortes do grupo, Brasil e Portugal, que realizam um evento científico bianual comum, o PROPOR2, e mantêm vínculos acadêmicos há várias décadas. Dois grandes repositórios de recursos e ferramentas linguístico-computacionais do Português, que pretendem abranger as diversas comunidades de língua portuguesa são a Linguateca3 e o Portulan Clarin4.Em países extensos como o Brasil, onde há uma grande variedade linguística, a exemplo das diferentes línguas indígenas faladas em território nacional5, das variações dialetais e sociais e dos sotaques regionais do português brasileiro, suas riquezas e diversidades linguísticas dificilmente são representadas nos corpora. Essa sub-representação nos dados de treinamento de modelos de aprendizado de máquina é um dos fatores que contribuem para aumentar a codificação de vieses por esses sistemas. Percebe-se, portanto, a importância de os dados linguísticos que alimentam tais sistemas serem coletados de forma responsável, buscando representar as variações linguísticas e idiomáticas das línguas faladas no país.Um dos primeiros corpora em português brasileiro usado para treinar um modelo de língua é o BrWac (Brazilian Portuguese Web as corpus), composto por 3,53 milhões de documentos da web, totalizando 2,68 bilhões de tokens, com acesso público para pesquisadores6. Já o corpus Carolina, do Centro de IA, C4AI7, é, de acordo com os autores, “um corpus com um volume robusto de textos em Português Brasileiro contemporâneo (1970-2021), com informações de procedência e tipologia. O corpus está disponível em acesso aberto, para download gratuito, desde 8 de março de 2022. A versão atual, Ada 1.2 (8 de março de 2023), tem 823 milhões de tokens, mais de dois milhões de textos e mais de 11 GBs”8. Esse corpus é um importante passo para o treinamento de LLM do português brasileiro, e tem o mérito de incluir uma grande variedade de gêneros (jornalismo, literatura, poesia, judiciário, wikis, mídia social, legislativo, acadêmico etc.), mas ainda não contempla as diversidades regionais e culturais dessa língua, meta perseguida pelo C4AI com a construção do corpus de fala (transcrições) TaRSila9, previsto para contemplar os diferentes dialetos brasileiros. Todos esses corpora pretendem ser variados quanto a gênero textual e domínio.No mesmo C4AI, o projeto PROINDL10 promete usar a IA em parceria com comunidades indígenas para o desenvolvimento de ferramentas que promovam a preservação, revitalização e disseminação de línguas indígenas do Brasil. Um dos objetivos é explorar as técnicas que utilizam poucos dados para criar tradutores automáticos tanto para texto como para fala, além de outras aplicações.Mesmo com a limitação de variedade e tamanho de corpora em português para treinamento de LLMs, grandes modelos de língua para o português já são encontrados, quer sejam modelos com capacidade multilíngue (ex. os modelos PALM da Google), quer sejam treinados apenas em português (ex. BERTimbau(Souza; Nogueira; Lotufo, 2020), Sabiá (Pires et al., 2023), Albertina11). Dessa forma, são claros os avanços em direção a produtos para a língua portuguesa. No entanto, o que pode parecer simples (corpus + redes neurais e Transformers + fine-tuning = LLM) pode ser, de fato, inviável. O custo de se produzir um LLM de qualidade é extremamente alto. Um ótimo LLM, como o LLaMA-65B, por exemplo, foi pré-treinado com 1.4 trilhão de palavras, em 40 mil GPU12-horas, consumindo energia equivalente ao consumo de cerca de 10 casas brasileiras em um ano13.De um lado, são necessárias muitas GPUs para treinar modelos competitivos: quanto maior o número de GPUs, mais parâmetros podem ser usados no modelo, aumentando sua eficácia numa tarefa. Atualmente, poucas instituições públicas ou privadas dispõem de infraestrutura para tal e, ainda assim, com número de GPUs bastante inferior (de 2 a 100) àquela disponível em nuvem (clusters de TPUs14) com preços de aluguel que podem chegar a um milhão de dólares. Pesquisadores costumam recorrer a recursos gratuitos e temporários oferecidos pelas gigantes internacionais (ex. Google Cloud). Essa dependência externa por recursos essenciais ao desenvolvimento tecnológico só pode ser minimizada por meio de ações e investimentos governamentais (p.ex. centralizados pelo CNPq) ou por iniciativas coletivas dos detentores de recursos no sentido de juntá-los para incrementar o poder computacional e compartilhá-lo com toda a comunidade. De outro lado, independentemente do fator financeiro, temos o custo energético, com efeito na emissão de carbono, que, como vimos, não é desprezível.Essas questões nos fazem refletir sobre os próximos caminhos a seguir. Nem tudo se resolve com grandes modelos de língua, assim como há muitas aplicações interessantes que podem ser desenvolvidas ou com modelos mais modestos ou por meios distintos dos modelos de língua. Considerando tarefas e domínios de conhecimento particulares, é possível construir soluções a partir de modelos treinados apenas nesse domínio. De fato, os resultados tendem a ser melhores do que com o uso de modelos mais genéricos. Além disso, considerar uma tarefa mais específica pode levar a uma solução - qualquer que seja a abordagem - mais eficaz.As limitações para a academia não impedem, no entanto, que o PLN seja cada vez mais usado por empresas e startups da área, cujo número vem crescendo muito em nosso país. Certamente isso é fruto da alta demanda por sistemas dessa natureza, mas também do investimento das universidades públicas na formação de recursos humanos nessa área. Estamos vivendo um momento de grande absorção dos profissionais de PLN pelo mercado. Mais um motivo para refletirmos sobre a formação desses profissionais frente aos grandes desafios que essa área (e a IA de modo geral) nos coloca.Além de todas as questões levantadas anteriormente, vale ressaltar a relevância de se adequar os critérios de avaliação tradicionalmente usados para sistemas de IA e, em particular, de PLN, à nova realidade das aplicações oferecidas à sociedade. A cultura acadêmica sugere uma avaliação em cenários rigidamente controlados, usando apenas métricas objetivas (numéricas), visando quase que exclusivamente a comparação com outros sistemas. Assim é a ciência e assim ela evolui. No entanto, tendo em vista o alcance que as novas tecnologias têm na sociedade, é urgente que os métodos de avaliação considerem critérios de outras naturezas, critérios que ajudem a prever o comportamento do sistema em situações, de fato, reais, sabidamente complexas, onde a imprevisibilidade é um fator relevante.A língua é frequentemente citada como sinal de inteligência e, por isso, nos distinguiria de outros animais. É por essa razão, aliás, que o PLN sempre esteve ligado à área de Inteligência Artificial. Sistemas dotados de habilidades linguísticas estariam entre os (artificialmente) inteligentes. No entanto, inteligência é algo difícil de se definir. Apenas parecer inteligente nos faz inteligentes? Essa questão sempre esteve presente na IA. Como definir um sistema inteligente? É necessário que ele raciocine como os humanos (seja bioinspirado), que tenha conhecimento explicitamente representado em seus algoritmos, ou basta que suas respostas sejam similares às de um humano nas mesmas situações? Não há acordo sobre isso, até porque sequer conseguimos concordar com os critérios de classificação de inteligência humana.No caso do PLN, isso se traduz na seguinte questão: aos sistemas que mostram habilidade linguística pode-se atribuir inteligência? Ainda: eles de fato dominam o conhecimento total sobre a língua e todos os fenômenos que a língua em uso nos apresenta?A língua tem sido objeto de estudo, análise e fascínio nas mais variadas áreas do conhecimento: filosofia, literatura, linguística, psicologia, psicanálise, ciências cognitivas, comunicação social, entre outras, e, recentemente, do PLN. Isso revela que a língua é um objeto de estudo bastante rico e complexo, e, portanto, não é possível abordá-lo segundo uma única disciplina.O PLN tem sido apresentado como uma área comum a duas disciplinas, Computação e Linguística. No passado, isso parecia suficiente, pois apenas a porção formal, estrutural da língua era tratada computacionalmente15. Com o passar do tempo, a evolução das máquinas e as redes sociais, isso mudou. Essa língua em uso no cenário digital atual só pode ser tratada de forma transdisciplinar. Não é um caminho simples, nem cômodo, nem garantidor de que o PLN terá sucesso. Pelo contrário, não é improvável que, ao tratar a língua em toda sua complexidade, concluamos que há um limite para o PLN que independe de avanços tecnológicos.Os capítulos anteriores evidenciam que PLN é uma área de grande potencial, porém repleta de desafios, sobre os quais é difícil fazer previsões. Várias tarefas de IA têm sido solucionadas pelas tecnologias atuais (Redes Neurais, Aprendizado de Máquina) que não são ideias novas; elas ficaram adormecidas até que o hardware das máquinas pudesse processá-las eficientemente. Em se tratando de PLN, no entanto, não é razoável prever que avanços de hardware, ou mesmo de métodos, garantam a solução completa para todos os sistemas que envolvem a língua. A demanda por sistemas que processam a língua não para de crescer. Vale notar que demandas e métodos são interdependentes: enquanto as demandas provocam novos métodos, estes últimos abrem caminho para novas demandas antes não possíveis.Este livro também evidenciou que o desempenho linguístico dos sistemas atuais de PLN espelham aquilo que aprendem a partir dos dados de treinamento dos algoritmos de aprendizado: língua na norma culta, língua mal formada, discursos de ódio, misoginia ou racismo; o que quer que tenha sido oferecido ao algoritmo de aprendizado a título de exemplo eventualmente será reproduzido pelo sistema gerado. Como o conhecimento (a língua) adquirido nesses sistemas não é explicitamente representado (ele está imerso em valores probabilísticos ou parâmetros numéricos das redes neurais), não há um controle de quando e como ele será usado. Todos esses efeitos colaterais dessa tecnologia preocupam a sociedade e trazem para a comunidade de PLN desafios e responsabilidades não existentes antes. As trajetórias da IA e do PLN têm nos ensinado que o alcance de metas mais modestas e realistas, ao longo do tempo, tem nos levado a patamares cada vez mais surpreendentes.Convidamos você a esperar para ver, ou fazer para acontecer.\"\n"
      ],
      "metadata": {
        "id": "RyUailD5vi9E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instalando e Configurando a API"
      ],
      "metadata": {
        "id": "WQ_MJ8XHDCWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalando a biblioteca\n",
        "!pip install openai==0.28.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqHXifVS-CHT",
        "outputId": "545e3f08-4211-4bfc-c157-bb3d9499bb2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import files\n",
        "\n",
        "# fazer upload do arquivo de texto\n",
        "upload_arquivo = files.upload()\n",
        "\n",
        "# obter o nome do arquivo\n",
        "nome_arquivo = list(upload_arquivo.keys())[0]\n",
        "\n",
        "# ler o conteúdo do arquivo\n",
        "with open(nome_arquivo, 'r') as file:\n",
        "   chave_api = file.read()\n",
        "\n",
        "# definir a chave da API\n",
        "openai.api_key = chave_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "1vfNPQGu_V1f",
        "outputId": "e67d988a-0ab1-4cbe-ea02-54030cac9b2e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b854c9dd-359e-4843-954e-923ad631f43f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b854c9dd-359e-4843-954e-923ad631f43f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving keyOpenAI.txt to keyOpenAI.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Configurando requisitos\n",
        "\n",
        "endpoint = endpoint = \"https://api.openai.com/v1/chat/completions\""
      ],
      "metadata": {
        "id": "JFpwvsSqFgKz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testes"
      ],
      "metadata": {
        "id": "9SgeA_JAGPb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Correção Gramátical"
      ],
      "metadata": {
        "id": "Az7jp0UaGrxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Capítulo 1"
      ],
      "metadata": {
        "id": "DdidzWuIchWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "mensagem_sistema = \"Você é um corretor gramátical avançado\"\n",
        "mensagem_usuario = f\"Procure por erros e apresente as correções para palavras escritas de maneira incorreta ou frases que não estejam em concordância verbal no seguinte texto: {cap1} \"\n",
        "mensagem_assistente = \"apresente a palavra ou frase incorreta e separe por '-' colocando a palavra ou frase correta logo depois, se não existirem, notifique. Ignore letras maíusculas e quebras de linha\"\n",
        "\n",
        "parametros = {\n",
        "   \"model\": \"gpt-3.5-turbo-0613\",\n",
        "   \"messages\": [\n",
        "      {\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "      {\"role\": \"user\", \"content\": mensagem_usuario},\n",
        "      {\"role\": \"assistant\", \"content\": mensagem_assistente}]\n",
        "}\n",
        "headers = {\n",
        "   \"Content-Type\": \"application/json\",\n",
        "   \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "}\n",
        "\n",
        "resposta = requests.post(endpoint, json=parametros, headers=headers)\n",
        "resposta.json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9adzMNkLICzB",
        "outputId": "23945ed9-3dc7-4ead-f162-fc605825bbf2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'chatcmpl-8PB3EMAvm0ETbYk7Tnq5xSSypz63Z',\n",
              " 'object': 'chat.completion',\n",
              " 'created': 1701011372,\n",
              " 'model': 'gpt-3.5-turbo-0613',\n",
              " 'choices': [{'index': 0,\n",
              "   'message': {'role': 'assistant',\n",
              "    'content': '- lingüas ==> línguas\\n- escrita (fala) ==> falada (fala)\\n- respostas mais ou menos bem-sucedidas do sistema para o significado tencionado pelo humano podem ser suficientes para muitas aplicações, e que o completo alinhamento entre o significado tencionado pelo humano e aquele interpretado pela máquina não deve ser parte das nossas expectativas. ==> respostas mais ou menos bem-sucedidas do sistema para o significado pretendido pelo humano podem ser suficientes para muitas aplicações, e que o completo alinhamento entre o significado pretendido pelo humano e aquele interpretado pela máquina não deve ser parte das nossas expectativas.\\n- qualquer que seja a modo ==> qualquer que seja o modo\\n- apreensão do significado de uma expressão linguistica ==> apreensão do significado de uma expressão linguística\\n- respostas ao usuário dos chatbots ==> respostas ao usuário de chatbots\\n- compartilham a dificuldade maior em PLN: ==> compartilham a maior dificuldade em PLN:\\n- os quais fornecem informações linguisticas ==> os quais fornecem informações linguísticas\\n- “toolkits”. ==> \"toolkits\".\\n- respostas ao usuário tendo uma entrada ou saída em linguagem natural ==> respostas ao usuário que têm entrada ou saída em linguagem natural\\n- que eles têm uma grande eloquência em serem bons modelos da língua. ==> que eles têm uma grande chance de serem bons modelos da língua.\\n- fugurar 1.1 ==> figura 1.1\\n- Os conceitos são caracterizados e exemplificados no quadro 1.1. ==> Os conceitos são caracterizados e exemplificados no Quadro 1.1.\\n- no núcleo, os sons e sua organizacao são estudados pela fonética e pela fonologia. ==> no núcleo, os sons e sua organização são estudados pela fonética e pela fonologia.\\n- A tradução automática, que deu notoriedade a esse paradigm, ==> A tradução automática, que deu notoriedade a esse paradigma,\\n- sendo cada um deles objeto de estudados de uma subárea ==> sendo cada um deles objeto de estudo de uma subárea\\n- um exemplo de aplicacao ==> um exemplo de aplicação\\n- as redes neurais também se baseiam em grandes volumes de dados para aprender um modelo; contudo, não'},\n",
              "   'finish_reason': 'length'}],\n",
              " 'usage': {'prompt_tokens': 3552,\n",
              "  'completion_tokens': 546,\n",
              "  'total_tokens': 4098}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(resposta.json()[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EPw9NOXS9j4",
        "outputId": "9a86c772-5ef8-46ed-ac47-ccce1d2661bf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- lingüas ==> línguas\n",
            "- escrita (fala) ==> falada (fala)\n",
            "- respostas mais ou menos bem-sucedidas do sistema para o significado tencionado pelo humano podem ser suficientes para muitas aplicações, e que o completo alinhamento entre o significado tencionado pelo humano e aquele interpretado pela máquina não deve ser parte das nossas expectativas. ==> respostas mais ou menos bem-sucedidas do sistema para o significado pretendido pelo humano podem ser suficientes para muitas aplicações, e que o completo alinhamento entre o significado pretendido pelo humano e aquele interpretado pela máquina não deve ser parte das nossas expectativas.\n",
            "- qualquer que seja a modo ==> qualquer que seja o modo\n",
            "- apreensão do significado de uma expressão linguistica ==> apreensão do significado de uma expressão linguística\n",
            "- respostas ao usuário dos chatbots ==> respostas ao usuário de chatbots\n",
            "- compartilham a dificuldade maior em PLN: ==> compartilham a maior dificuldade em PLN:\n",
            "- os quais fornecem informações linguisticas ==> os quais fornecem informações linguísticas\n",
            "- “toolkits”. ==> \"toolkits\".\n",
            "- respostas ao usuário tendo uma entrada ou saída em linguagem natural ==> respostas ao usuário que têm entrada ou saída em linguagem natural\n",
            "- que eles têm uma grande eloquência em serem bons modelos da língua. ==> que eles têm uma grande chance de serem bons modelos da língua.\n",
            "- fugurar 1.1 ==> figura 1.1\n",
            "- Os conceitos são caracterizados e exemplificados no quadro 1.1. ==> Os conceitos são caracterizados e exemplificados no Quadro 1.1.\n",
            "- no núcleo, os sons e sua organizacao são estudados pela fonética e pela fonologia. ==> no núcleo, os sons e sua organização são estudados pela fonética e pela fonologia.\n",
            "- A tradução automática, que deu notoriedade a esse paradigm, ==> A tradução automática, que deu notoriedade a esse paradigma,\n",
            "- sendo cada um deles objeto de estudados de uma subárea ==> sendo cada um deles objeto de estudo de uma subárea\n",
            "- um exemplo de aplicacao ==> um exemplo de aplicação\n",
            "- as redes neurais também se baseiam em grandes volumes de dados para aprender um modelo; contudo, não\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Capítulo 25"
      ],
      "metadata": {
        "id": "BWbdE_BzTylh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mensagem_usuario = f\"Procure por erros e apresente as correções para palavras escritas de maneira incorreta ou frases que não estejam em concordância verbal no seguinte texto: {cap25} \"\n",
        "\n",
        "parametros = {\n",
        "   \"model\": \"gpt-3.5-turbo-0613\",\n",
        "   \"messages\": [\n",
        "      {\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "      {\"role\": \"user\", \"content\": mensagem_usuario},\n",
        "      {\"role\": \"assistant\", \"content\": mensagem_assistente}]\n",
        "}\n",
        "headers = {\n",
        "   \"Content-Type\": \"application/json\",\n",
        "   \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "}\n",
        "\n",
        "resposta = requests.post(endpoint, json=parametros, headers=headers)\n",
        "resposta.json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hj1nnWqT6rl",
        "outputId": "99680add-336d-4c26-e23d-87eb6cb08892"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'chatcmpl-8PB7FrjIoGNm565ajTfr2C45SjAaz',\n",
              " 'object': 'chat.completion',\n",
              " 'created': 1701011621,\n",
              " 'model': 'gpt-3.5-turbo-0613',\n",
              " 'choices': [{'index': 0,\n",
              "   'message': {'role': 'assistant',\n",
              "    'content': '- perspectivas - Perspectivas\\n- PLN - processamento de linguagem natural \\n- estado da arte - estado-da-arte \\n- outras comunidades têm adaptado - outras comunidades têm se adaptado\\n- comunidades linguísticas minoritárias - comunidades linguísticas de minorias \\n- organização não falantes do português - organizações que não falam português \\n- a comunidade de falantes de português no mundo era estimada - a comunidade de falantes de português no mundo era estimada em \\n- estimada em cerca - estimada em cerca de \\n- 3,7% da população mundial - 3,7% da população mundial,\\n- que ele merece1 - que ele merece.\\n- treinamentos - treinamento\\n- além do Brasil - além do Brasil.\\n- treinados apenas em português - treinados apenas em português,\\n- bem como domínios de conhecimento - bem como nos domínios de conhecimento\\n- com preços de aluguel - com preços de aluguel que\\n- PLN pelo mercado - PLN pelo mercado.\\n- Inteligência Artificial - inteligência artificial\\n- o PLN sempre esteve ligado - o PLN sempre esteve ligado à\\n- ter conhecimento explicitamente representado - ter conhecimento representado explicitamente\\n- com outros sistemas. - com outros sistemas\\n- (numéricas), visando - (numéricas) visando\\n- que ajudem a prever - que ajudem a preverem\\n- situações, de fato, - situações de fato,\\n- dominam o conhecimento - dominam os conhecimentos\\n- transdisciplinar. Não é um caminho - transdisciplinar, não é um caminho\\n- eficientemente. Em se tratando - eficientemente. Em se tratando de\\n- das máquinas pudesse - das máquinas puderem\\n- que envolvem a língua - que envolvem a língua.\\n- reproduzido pelo sistema - reproduzido pelo sistema.\\n- explicitamente representado (ele está - explicitamente representado, ele está\\n- quaisquer efeitos colaterais - todos os efeitos colaterais'},\n",
              "   'finish_reason': 'stop'}],\n",
              " 'usage': {'prompt_tokens': 3505,\n",
              "  'completion_tokens': 498,\n",
              "  'total_tokens': 4003}}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(resposta.json()[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHsZtLAOcZcC",
        "outputId": "14e6234d-3432-49c5-ab87-d6620accade3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- perspectivas - Perspectivas\n",
            "- PLN - processamento de linguagem natural \n",
            "- estado da arte - estado-da-arte \n",
            "- outras comunidades têm adaptado - outras comunidades têm se adaptado\n",
            "- comunidades linguísticas minoritárias - comunidades linguísticas de minorias \n",
            "- organização não falantes do português - organizações que não falam português \n",
            "- a comunidade de falantes de português no mundo era estimada - a comunidade de falantes de português no mundo era estimada em \n",
            "- estimada em cerca - estimada em cerca de \n",
            "- 3,7% da população mundial - 3,7% da população mundial,\n",
            "- que ele merece1 - que ele merece.\n",
            "- treinamentos - treinamento\n",
            "- além do Brasil - além do Brasil.\n",
            "- treinados apenas em português - treinados apenas em português,\n",
            "- bem como domínios de conhecimento - bem como nos domínios de conhecimento\n",
            "- com preços de aluguel - com preços de aluguel que\n",
            "- PLN pelo mercado - PLN pelo mercado.\n",
            "- Inteligência Artificial - inteligência artificial\n",
            "- o PLN sempre esteve ligado - o PLN sempre esteve ligado à\n",
            "- ter conhecimento explicitamente representado - ter conhecimento representado explicitamente\n",
            "- com outros sistemas. - com outros sistemas\n",
            "- (numéricas), visando - (numéricas) visando\n",
            "- que ajudem a prever - que ajudem a preverem\n",
            "- situações, de fato, - situações de fato,\n",
            "- dominam o conhecimento - dominam os conhecimentos\n",
            "- transdisciplinar. Não é um caminho - transdisciplinar, não é um caminho\n",
            "- eficientemente. Em se tratando - eficientemente. Em se tratando de\n",
            "- das máquinas pudesse - das máquinas puderem\n",
            "- que envolvem a língua - que envolvem a língua.\n",
            "- reproduzido pelo sistema - reproduzido pelo sistema.\n",
            "- explicitamente representado (ele está - explicitamente representado, ele está\n",
            "- quaisquer efeitos colaterais - todos os efeitos colaterais\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Sumarização de Texto"
      ],
      "metadata": {
        "id": "X8lZq-N8410W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Capítulo 1"
      ],
      "metadata": {
        "id": "l0x92NUp8YVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mensagem_sistema = \"Você é especialista em análise de textos de artigos\"\n",
        "mensagem_usuario = f\"Extraia as palavras-chave do seguinte texto: \\n {cap1} \"\n",
        "mensagem_assistente = \"Liste 10 palavras ou expressões principais que resumem o texto\"\n",
        "\n",
        "parametros = {\n",
        "   \"model\": \"gpt-3.5-turbo-0613\",\n",
        "   \"messages\": [\n",
        "      {\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "      {\"role\": \"user\", \"content\": mensagem_usuario},\n",
        "      {\"role\": \"assistant\", \"content\": mensagem_assistente}]\n",
        "}\n",
        "headers = {\n",
        "   \"Content-Type\": \"application/json\",\n",
        "   \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "}\n",
        "\n",
        "resposta = requests.post(endpoint, json=parametros, headers=headers)\n",
        "resposta.json()\n",
        "print(resposta.json()[\"choices\"][0][\"message\"][\"content\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kTOgmhm7LZ9",
        "outputId": "d82b0669-350f-497d-ac5f-7180b257a6bf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Processamento de Linguagem Natural\n",
            "2. Campo de pesquisa\n",
            "3. Língua escrita e falada\n",
            "4. Inteligência Artificial\n",
            "5. Interpretação de Linguagem Natural\n",
            "6. Geração de Linguagem Natural\n",
            "7. Aplicações, recursos e ferramentas\n",
            "8. Paradigmas do PLN\n",
            "9. Aprendizado de máquina\n",
            "10. Redes neurais profundas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Capítulo 25"
      ],
      "metadata": {
        "id": "11ET3Rcd_xWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mensagem_sistema = \"Você é especialista em análise de textos de artigos\"\n",
        "mensagem_usuario = f\"Extraia as palavras-chave do seguinte texto: {cap25} \"\n",
        "mensagem_assistente = \"Liste 10 palavras ou expressões principais que resumem o texto\"\n",
        "\n",
        "parametros = {\n",
        "   \"model\": \"gpt-3.5-turbo-0613\",\n",
        "   \"messages\": [\n",
        "      {\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "      {\"role\": \"user\", \"content\": mensagem_usuario},\n",
        "      {\"role\": \"assistant\", \"content\": mensagem_assistente}]\n",
        "}\n",
        "headers = {\n",
        "   \"Content-Type\": \"application/json\",\n",
        "   \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "}\n",
        "\n",
        "resposta = requests.post(endpoint, json=parametros, headers=headers)\n",
        "resposta.json()\n",
        "print(resposta.json()[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2zHpYxc_xtn",
        "outputId": "83ad12ec-5a68-489a-b7b4-299e9c9643bf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. PLN (Processamento de Linguagem Natural)\n",
            "2. Língua portuguesa\n",
            "3. Desafios e perspectivas\n",
            "4. Comunidades linguísticas minoritárias\n",
            "5. Dados de treinamento\n",
            "6. Corpora (conjunto de textos)\n",
            "7. Modelos de aprendizado de máquina\n",
            "8. Infraestrutura computacional\n",
            "9. Formação de profissionais de PLN\n",
            "10. Responsabilidade e ética na IA e PLN.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Tradução de Expressões"
      ],
      "metadata": {
        "id": "W_mFKog4CSxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Capítulo 1"
      ],
      "metadata": {
        "id": "tV-xPSthvX2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mensagem_sistema = \"Você é especialista em análise de textos de artigos\"\n",
        "mensagem_usuario = f\"Identifique as palavras de origem inglesa no texto a seguir e depois apresente sua tradução: {cap1} \"\n",
        "mensagem_assistente = \"Liste as palavras de origem inglesa e na frente coloque sua tradução em português, separe por '-'. Caso não exista palavras de origem inglesa, notifique\"\n",
        "\n",
        "parametros = {\n",
        "   \"model\": \"gpt-3.5-turbo-0613\",\n",
        "   \"messages\": [\n",
        "      {\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "      {\"role\": \"user\", \"content\": mensagem_usuario},\n",
        "      {\"role\": \"assistant\", \"content\": mensagem_assistente}]\n",
        "}\n",
        "headers = {\n",
        "   \"Content-Type\": \"application/json\",\n",
        "   \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "}\n",
        "\n",
        "resposta = requests.post(endpoint, json=parametros, headers=headers)\n",
        "resposta.json()\n",
        "print(resposta.json()[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FRdfn7bCXr6",
        "outputId": "ab96b882-062f-4a3b-cc49-daa908fff3d1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Natural Language Processing (Processamento de Linguagem Natural)\n",
            "- Natural Language Understanding (Interpretação de Linguagem Natural)\n",
            "- Natural Language Generation (Geração de Linguagem Natural)\n",
            "- Artificial Intelligence (Inteligência Artificial)\n",
            "- toolkit (conjunto de ferramentas)\n",
            "- chatbot (robô de conversação)\n",
            "- ChatGPT2 (modelo de geração de linguagem natural)\n",
            "- corpus (conjunto de textos)\n",
            "- deep learning (aprendizado profundo)\n",
            "- machine learning (aprendizado de máquina)\n",
            "- AI (Artificial Intelligence - Inteligência Artificial)\n",
            "- NLP (Natural Language Processing - Processamento de Linguagem Natural)\n",
            "- NLU (Natural Language Understanding - Interpretação de Linguagem Natural)\n",
            "- NLG (Natural Language Generation - Geração de Linguagem Natural)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Capítulo 25"
      ],
      "metadata": {
        "id": "aPrFBdhbvg6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mensagem_sistema = \"Você é especialista em análise de textos de artigos\"\n",
        "mensagem_usuario = f\"Identifique as palavras de origem inglesa no texto a seguir e depois apresente sua tradução: {cap25} \"\n",
        "mensagem_assistente = \"Liste as palavras de origem inglesa e na frente coloque sua tradução em português, separe por '-'. Caso não exista palavras de origem inglesa, notifique\"\n",
        "parametros = {\n",
        "   \"model\": \"gpt-3.5-turbo-0613\",\n",
        "   \"messages\": [\n",
        "      {\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "      {\"role\": \"user\", \"content\": mensagem_usuario},\n",
        "      {\"role\": \"assistant\", \"content\": mensagem_assistente}]\n",
        "}\n",
        "headers = {\n",
        "   \"Content-Type\": \"application/json\",\n",
        "   \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "}\n",
        "\n",
        "resposta = requests.post(endpoint, json=parametros, headers=headers)\n",
        "resposta.json()\n",
        "print(resposta.json()[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BPNUHxiDDrV",
        "outputId": "6888e2d5-8e3a-448d-a480-9c564d6338a3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- PLN (Processamento de Linguagem Natural) - NLP (Natural Language Processing)\n",
            "- estado da arte - state of the art\n",
            "- community - comunidade\n",
            "- dataset - conjunto de dados\n",
            "- training - treinamento\n",
            "- machine learning - aprendizado de máquina\n",
            "- cross-language - multilíngue\n",
            "- native - nativas\n",
            "- corpus - corpora\n",
            "- IA (Inteligência Artificial) - AI (Artificial Intelligence)\n",
            "- modelos de linguagem - language models\n",
            "- fine-tuning - ajuste fino\n",
            "- GPUs - GPUs\n",
            "- clusters - clusters\n",
            "- benchmarks - benchmarks\n",
            "- big data - big data\n",
            "- datasets - conjuntos de dados\n",
            "- neural networks - redes neurais\n",
            "- datasets de treinamento - conjuntos de dados de treinamento\n"
          ]
        }
      ]
    }
  ]
}